{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python to Search and Retrieve Data from the Elsevier Scopus Database\n",
    "\n",
    "Vincent Scalfani and Lance Simpson, Univ. of Alabama Libraries\n",
    "\n",
    "These examples use the Elsevier Scopus API and the Python Scopus API-wrapper package, [pybliometrics](https://pybliometrics.readthedocs.io/en/stable/). Code was tested and sample data downloaded from the Scopus API on September 29, 2022 via http://api.elsevier.com and http://www.scopus.com. This tutorial content is intended to help facillitate academic research. Before continuing or reusing any of this code, please be aware of Elsevier's [API policies and appropiate use-cases](https://dev.elsevier.com/use_cases.html). You will also need to register with the [Elsevier Developer Portal](https://dev.elsevier.com/) to request an API key in order to use the Scopus API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conda Environment Setup\n",
    "\n",
    "We are going to use the Ana(conda) package mangager to setup our Python/Scopus development environment. See the documentation for [managing environments](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html).\n",
    "\n",
    "Here is the recipe we will use within the Anaconda Prompt Terminal:\n",
    "\n",
    "```console\n",
    "conda create --name my-scopus-env\n",
    "conda activate my-scopus-env\n",
    "conda install -c conda-forge jupyterlab matplotlib pandas pip\n",
    "pip install pybliometrics\n",
    "\n",
    "```\n",
    "\n",
    "To launch a jupyter notebook, type ``jupyter lab``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. A five minute introduction to Pandas [1,2]\n",
    "\n",
    "We'll use Pandas dataframes for working with the pybliometrics returned Scopus data. [pandas](https://pandas.pydata.org/) is a popular Python library for data analysis and manipulation. The library extends the functionality of working with structured arrays in [NumPy](https://numpy.org/). See our previous workshops for more about Pandas: https://github.com/ualibweb/UALIB_Workshops\n",
    "\n",
    "A pandas [Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html) is a one-dimensional array, while a [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame) is a two-dimensional array (e.g., multiple columns). Both the Series and DataFrame structures contain an index [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import with common alias for numpy (np) and pandas (pd):\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some pandas series\n",
    "# data from https://en.wikipedia.org/wiki/Melting_points_of_the_elements_(data_page)\n",
    "\n",
    "atomic_number = pd.Series([4, 12, 20, 38, 56, 88])\n",
    "symbol = pd.Series(['Be', 'Mg', 'Ca', 'Sr', 'Ba', 'Ra'])\n",
    "melting_point = pd.Series([1287, 923, 842, 777, 727, 700]) # celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame with headings from our data series\n",
    "df = pd.DataFrame({'atomic_number': atomic_number, 'symbol': symbol, 'melting_point': melting_point})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also create our own named index if we want:\n",
    "myindex = pd.Series(['Elem0', 'Elem1', 'Elem2', 'Elem3', 'Elem4', 'Elem5'])\n",
    "df['myindex'] = myindex\n",
    "df.set_index('myindex', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info, also try help(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "[1] https://jakevdp.github.io/PythonDataScienceHandbook/\n",
    "\n",
    "[2] https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Indexing\n",
    "\n",
    "There are two main ways to select subsets of a DataFrame via indexing [3,6].\n",
    "\n",
    "1. [pd.DataFrame.iloc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html): The iloc property uses integer based indexing (e.g., `[i,j]`, where `i` is the row, and `j` is the column).\n",
    "\n",
    "2. [pd.DataFrame.loc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc): The loc property is label based (e.g., `[row_name, col_name]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a value at position row 0, col 0\n",
    "df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now with loc\n",
    "df.loc['Elem0','atomic_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a value at position row 0, col 1\n",
    "df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now with loc\n",
    "df.loc['Elem0','symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select an entire row or column\n",
    "# iloc select all rows, column index position 2\n",
    "df.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc equivalent\n",
    "df.loc[:,'melting_point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also use dot indexing\n",
    "df.melting_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.melting_point[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "[3] http://swcarpentry.github.io/python-novice-gapminder/08-data-frames/index.html\n",
    "\n",
    "[4] https://stackoverflow.com/questions/17071871/how-to-select-rows-from-a-dataframe-based-on-column-values\n",
    "\n",
    "[5] https://stackoverflow.com/questions/27975069/how-to-filter-rows-containing-a-string-pattern-from-a-pandas-dataframe\n",
    "\n",
    "[6] https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Operations\n",
    "\n",
    "See doc: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the max of a column\n",
    "df.melting_point.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return index position\n",
    "df.melting_point.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sum\n",
    "df.melting_point.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a column to a python list\n",
    "a = df.atomic_number.tolist()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's also possible to plot data directly from a DataFrame:\n",
    "import matplotlib.pyplot as plt\n",
    "df.plot.scatter(x = \"atomic_number\", y = \"melting_point\")\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "plt.ylabel('Melting Point (celsius)', size=16)\n",
    "plt.xlabel('Atomic Number', size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Python For Loops [7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`for` loops allow repeated execution of code on a known collection of values such as a range of numbers or a list. A general syntax example is as follows:\n",
    "\n",
    "```python\n",
    "for item in items:\n",
    "  do something\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put variables in a list\n",
    "subjects = [\"Nursing\", \"Engineering\", \"Math\", \"Science\"]\n",
    "\n",
    "for subject in subjects:\n",
    "    print(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is another way using an index value\n",
    "for i in range(len(subjects)):\n",
    "    print(subjects[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And even one more way! :)\n",
    "for i, subject in enumerate(subjects):\n",
    "    print(i, subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the returned Scopus data, we will make use of Python's ability to have lists within lists, and then will reformat this data for further analysis. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the use of \\ here is for clarity, so we can put one list set per line\n",
    "r = \\\n",
    "['vin',['batman','superman'],[100,90]],\\\n",
    "['tim',['Thor'],[80]], \\\n",
    "['amy',['guardians','venom','x-men','spiderman'],[95,90,70,80]]\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outline of how to index into r\n",
    "# load our scanned drawing\n",
    "from IPython.display import Image\n",
    "Image(filename='indexing_help.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the indexing within this list and then \"flatten\" the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First \"row\" or list within the list\n",
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element 0\n",
    "r[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element 1 within list 0\n",
    "r[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one more level\n",
    "r[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element 2\n",
    "r[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all names\n",
    "names = []\n",
    "for idx in range(len(r)):\n",
    "    names.append(r[idx][0])  # list index, 0 for the first entry\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all movie names\n",
    "movies = []\n",
    "for idx in range(len(r)):\n",
    "    movies.append(r[idx][1])  # same list index, but now 1 for second position\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still a list of lists, so we can \"flatten\" this more with two loops\n",
    "movies_flat = []\n",
    "for idx in range(len(r)): # length of lists of lists\n",
    "    for movie_idx in range(len(r[idx][1])): # length of individual list of movies             \n",
    "        movies_flat.append(r[idx][1][movie_idx]) # gets actual movie within list of movies\n",
    "movies_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add other data to make the entire original list flat\n",
    "r_flat = []\n",
    "for idx in range(len(r)): # length of lists of lists\n",
    "    for movie_idx in range(len(r[idx][1])): # length of indivudual list of movies             \n",
    "        r_flat.append([r[idx][0], r[idx][1][movie_idx], r[idx][2][movie_idx]])\n",
    "r_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "    \n",
    "[7] https://nbviewer.jupyter.org/github/jakevdp/WhirlwindTourOfPython/blob/master/07-Control-Flow-Statements.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initial Pybliometrics Setup\n",
    "\n",
    "The first time you run `import pybliometrics`, it will prompt you for your Elsevier Scopus API Key (apply for one here: https://dev.elsevier.com/),\n",
    "which is then saved to a local config file. See the documentation:\n",
    "https://pybliometrics.readthedocs.io/en/stable/configuration.html\n",
    "\n",
    "**N.B. Keep your API key a secret**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybliometrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import time (we'll use this later for delays)\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scopus APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scopus has a variety of different APIs, some of which are implemented in pybliometrics:\n",
    "\n",
    "https://dev.elsevier.com/sc_api_spec.html\n",
    "\n",
    "https://pybliometrics.readthedocs.io/en/stable/classes.html\n",
    "\n",
    "Let's take a look at a few of the APIs:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract Retrieval API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pybliometrics.readthedocs.io/en/stable/classes/AbstractRetrieval.html\n",
    "\n",
    "from pybliometrics.scopus import AbstractRetrieval\n",
    "a = AbstractRetrieval(\"2-s2.0-85109133923\", view='FULL') # eid Elsevier identifier (we'll see how to get these below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are > 50 different properties that you can extract.\n",
    "# here are a few as examples:\n",
    "\n",
    "a.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.openaccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PlumX API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pybliometrics.readthedocs.io/en/stable/classes/PlumXMetrics.html\n",
    "\n",
    "from pybliometrics.scopus import PlumXMetrics\n",
    "plum1 = PlumXMetrics(\"10.1186/1758-2946-3-33\", id_type='doi')\n",
    "print(plum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plum1.citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a dataFrame:\n",
    "df_capture1 = pd.DataFrame(plum1.capture)\n",
    "df_citation1 = pd.DataFrame(plum1.citation)\n",
    "df_mention1 = pd.DataFrame(plum1.mention)\n",
    "df_social1 = pd.DataFrame(plum1.social_media)\n",
    "df_use1 = pd.DataFrame(plum1.usage)\n",
    "\n",
    "frames1 = [df_capture1, df_citation1, df_mention1, df_social1, df_use1]\n",
    "df_totals1 = pd.concat(frames1)\n",
    "df_totals1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scopus Search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Doc: https://pybliometrics.readthedocs.io/en/stable/classes/ScopusSearch.html\n",
    "# We can use standard field limiters like Abstract, Title, etc:\n",
    "# Search Tips: https://dev.elsevier.com/sc_search_tips.html\n",
    "\n",
    "from pybliometrics.scopus import ScopusSearch\n",
    "\n",
    "# search for \"chemical fingerprint\" in the record abstract and \"cheminformatics\" in doc source title\n",
    "q0 = ScopusSearch('ABS(\"chemical fingerprint\") AND SRCTITLE (cheminformatics)', download=False)\n",
    "q0.get_results_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Records for Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scopus Author ID field (AU-ID): 7103233705, Frank S. Bates (Univ. of Minnesota)\n",
    "q1 = ScopusSearch('AU-ID(7103233705)', download=False)\n",
    "q1.get_results_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Record Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = ScopusSearch('AU-ID(7103233705)', download=True)\n",
    "\n",
    "# save to dataframe\n",
    "df1 = pd.DataFrame(q1.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view column names\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 5 rows\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can index data from our new dataframe, df1.\n",
    "# For example, create a list of just the DOIs\n",
    "dois = df1.doi.tolist()\n",
    "dois[0:20] # print first 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of article titles\n",
    "titles = df1.title.tolist()\n",
    "titles[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now a list of the cited by count\n",
    "cited_by = df1.citedby_count.tolist()\n",
    "cited_by[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sum of cited_by counts\n",
    "sum(cited_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max cited_by\n",
    "df1.citedby_count.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.citedby_count.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the data for the idxmax value\n",
    "df1.iloc[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a summary of statistics\n",
    "df1.citedby_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a quick histogram\n",
    "import matplotlib.pyplot as plt\n",
    "df1.loc[:,'citedby_count'].hist(bins=75)\n",
    "plt.ylabel('Frequency', size=16)\n",
    "plt.xlabel('citedby', size=16)\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(0,1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automate several searches with a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_list = [['Emy Decker', '36660678600'], ['Lindsey Lowry', '57210944451'], \n",
    "               ['Karen Chapman', '35783926100'], ['Kevin Walker', '56133961300'], \n",
    "               ['Sara Whitver', '57194760730']]\n",
    "\n",
    "\n",
    "# Alternatively if you want to load data from file:\n",
    "\n",
    "# import csv\n",
    "# with open('authors.txt') as infile:\n",
    "#           rows = csv.reader(infile, delimiter='\\t')\n",
    "#           author_list = list(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of Scopus records for each author\n",
    "num_records = []\n",
    "for author,authorID in author_list:\n",
    "    \n",
    "    # query search\n",
    "    q = ScopusSearch('AU-ID' +'(' + authorID + ')', download=False)\n",
    "    num = q.get_results_size()\n",
    "    \n",
    "    # compile saved scopus data into a list of lists               \n",
    "    num_records.append([author, authorID, num])\n",
    "    \n",
    "    # delay one second between api calls to be nice to Elsevier servers\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Record Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want the DOIs and cited by counts in a list\n",
    "cites = []\n",
    "for author,authorID in author_list:\n",
    "    \n",
    "    # query search\n",
    "    q = ScopusSearch('AU-ID' +'(' + authorID + ')')\n",
    "    \n",
    "    # create a dataframe\n",
    "    q_df = pd.DataFrame(q.results)\n",
    "       \n",
    "    # save DOIs to a list\n",
    "    doi = q_df.doi.tolist()\n",
    "    \n",
    "    # save citedby_count to a list\n",
    "    citedby_count = q_df.citedby_count.tolist()\n",
    "       \n",
    "    # compile saved scopus data into a list of lists               \n",
    "    cites.append([author, doi, citedby_count])\n",
    "    \n",
    "    # delay one second between api calls to be nice to Elsevier servers\n",
    "    time.sleep(1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cites variable is a list of list with the data\n",
    "# view data for first three authors\n",
    "cites[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can transform this into a flat list as follows\n",
    "cites_flat = []\n",
    "for authors in range(len(cites)):\n",
    "    for doi in range(len(cites[authors][1])):\n",
    "        cites_flat.append([cites[authors][0], cites[authors][1][doi], cites[authors][2][doi]])\n",
    "cites_flat[0:25] # show first 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to dataframe\n",
    "cites_df = pd.DataFrame(cites_flat)\n",
    "cites_df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Record Data to a file\n",
    "\n",
    "Here is one method if you want to loop over author queries and save all Scopus document data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(author_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "##################\n",
    "\n",
    "# ****this writes one file for each author dataset in your current directory*****\n",
    "\n",
    "##################\n",
    "##################\n",
    "\n",
    "for authorName,authorID in author_list:\n",
    "    \n",
    "    # create new empty dataFrame on each loop\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # query search by Author ID\n",
    "    q = ScopusSearch('AU-ID' +'(' + authorID + ')')\n",
    "    \n",
    "    # convert to dataframe\n",
    "    df = pd.DataFrame(q.results)\n",
    "    \n",
    "    # Save to file\n",
    "    df.to_csv(str(authorName).replace(' ','_') + \"_\" + str(authorID) + \"_ScopusData\" + \".tsv\", sep = '\\t', index=False)\n",
    "    \n",
    "    # delay two seconds between api calls to be nice to Elsevier servers\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one of the files into pandas\n",
    "df_author3 = pd.read_csv('Karen_Chapman_35783926100_ScopusData.tsv', delimiter='\\t')\n",
    "df_author3.head(5) # view first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info about citedby_count\n",
    "df_author3.citedby_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info about publication titles\n",
    "df_author3.publicationName.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try a Title Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Scopus for all references containing 'ChemSpider' in the record title\n",
    "q2 = ScopusSearch('TITLE(chemspider)',download=False)\n",
    "q2.get_results_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat this in a loop for several different searches\n",
    "titleWord_list = ['chemspider', 'pubchem', 'chembl', 'reaxys', 'scifinder']\n",
    "\n",
    "# get number of Scopus records for each title search\n",
    "num_records_title = []\n",
    "for titleWord in titleWord_list:\n",
    "    \n",
    "    # query search\n",
    "    qt = ScopusSearch('TITLE' +'(' + titleWord + ')',download=False)\n",
    "    numt = qt.get_results_size()\n",
    "    \n",
    "    # compile saved scopus data into a list of lists               \n",
    "    num_records_title.append([titleWord,numt])\n",
    "    \n",
    "    # delay one second between api calls to be nice to Elsevier servers\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_records_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Title Match Record Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download records and create a list of selected metadata\n",
    "titleWord_list = ['chemspider', 'pubchem', 'chembl', 'reaxys', 'scifinder']\n",
    "scopus_title_data = []\n",
    "\n",
    "for titleWord in titleWord_list:\n",
    "    \n",
    "    # query search\n",
    "    qt = ScopusSearch('TITLE' +'(' + titleWord + ')') \n",
    "    \n",
    "    # create the dataframe\n",
    "    qt_df = pd.DataFrame(qt.results)\n",
    "    \n",
    "    # save DOIs to a list\n",
    "    doi = qt_df.doi.tolist()\n",
    "    \n",
    "    # save title to a list\n",
    "    title = qt_df.title.tolist()\n",
    "\n",
    "    # save coverDate to a list\n",
    "    coverDate = qt_df.coverDate.tolist()\n",
    "    \n",
    "    # compile saved scopus_title_data into a list of lists               \n",
    "    scopus_title_data.append([titleWord, doi, title, coverDate])\n",
    "    \n",
    "    # delay one second between api calls to be nice to Elsevier servers\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus_title_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a flat list of scopus_title_data\n",
    "scopus_title_data_flat = []\n",
    "for titleWord in range(len(scopus_title_data)):\n",
    "    for doi in range(len(scopus_title_data[titleWord][1])):\n",
    "        scopus_title_data_flat.append([scopus_title_data[titleWord][0], # titleWord\n",
    "                                       scopus_title_data[titleWord][1][doi], # doi\n",
    "                                       scopus_title_data[titleWord][2][doi], # title\n",
    "                                       scopus_title_data[titleWord][3][doi]]) # coverdate\n",
    "\n",
    "scopus_title_data_flat[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to dataFrame\n",
    "title_df = pd.DataFrame(scopus_title_data_flat)\n",
    "\n",
    "\n",
    "title_df.rename(columns={0:\"titleWord\",1: \"doi\",2: \"title\", 3: \"coverDate\"},\n",
    "                            inplace=True)\n",
    "\n",
    "\n",
    "pd.options.display.max_rows = 30\n",
    "title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column with just the year of coverDate and convert to numeric\n",
    "title_df['coverDate_year'] = title_df.coverDate.str[:4]\n",
    "title_df['coverDate_year'] = pd.to_numeric(title_df['coverDate_year'])\n",
    "title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter rows for ChEMBL results\n",
    "chembl_df = title_df.loc[title_df['titleWord'].str.contains(\"chembl\")]\n",
    "chembl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts by year and sort\n",
    "chembl_df.loc[:,'coverDate_year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a bar graph of chembl matches in Scopus by year\n",
    "chembl_df.loc[:,'coverDate_year'].value_counts().sort_index().plot.bar(color='darkseagreen')\n",
    "plt.ylabel(\"Number of ChEMBL title occurances\", size=12)\n",
    "plt.xlabel('Year', size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before leaving, restart your computer to clear any conda and config data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
